# -*- coding: utf-8 -*-
"""Maritime Obj Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YIRa4B36oM-47dzjhSz-9T3ApeiZhI3k
"""

# Install dependencies (run once)
!pip install -U ultralytics opencv-python pycocotools tqdm pyyaml

import os
import json
import cv2
import yaml
from tqdm import tqdm
from pycocotools.coco import COCO
from ultralytics import YOLO

# Root paths (EDIT ONLY IF NEEDED)
RAW_DATASET = "dataset"                 # original compressed dataset
YOLO_DATASET = "dataset_yolo"           # after COCO→YOLO
TILED_DATASET = "dataset_tiled"         # after tiling

#COCO to YOLO
def coco_to_yolo(coco_json, img_dir, out_img_dir, out_lbl_dir):
    os.makedirs(out_img_dir, exist_ok=True)
    os.makedirs(out_lbl_dir, exist_ok=True)

    coco = COCO(coco_json)
    cat_ids = coco.getCatIds()
    cat_map = {cat_id: i for i, cat_id in enumerate(cat_ids)}

    for img_id in tqdm(coco.getImgIds(), desc="COCO → YOLO"):
        img_info = coco.loadImgs(img_id)[0]
        fname = img_info["file_name"]

        src_img = os.path.join(img_dir, fname)
        if not os.path.exists(src_img):
            continue

        img = cv2.imread(src_img)
        h, w, _ = img.shape

        cv2.imwrite(os.path.join(out_img_dir, fname), img)

        ann_ids = coco.getAnnIds(imgIds=img_id)
        anns = coco.loadAnns(ann_ids)

        label_file = os.path.join(out_lbl_dir, fname.replace(".jpg", ".txt"))

        with open(label_file, "w") as f:
            for ann in anns:
                if ann.get("iscrowd", 0):
                    continue
                x, y, bw, bh = ann["bbox"]
                xc = (x + bw / 2) / w
                yc = (y + bh / 2) / h
                bw /= w
                bh /= h
                cls = cat_map[ann["category_id"]]
                f.write(f"{cls} {xc} {yc} {bw} {bh}\n")

# Train split
coco_to_yolo(
    coco_json="dataset/annotations/instances_train.json",
    img_dir="dataset/images/train",
    out_img_dir="dataset_yolo/images/train",
    out_lbl_dir="dataset_yolo/labels/train"
)

# Validation split
coco_to_yolo(
    coco_json="dataset/annotations/instances_val.json",
    img_dir="dataset/images/val",
    out_img_dir="dataset_yolo/images/val",
    out_lbl_dir="dataset_yolo/labels/val"
)

#Image Tiling
def tile_image(img_path, label_path, out_img_dir, out_lbl_dir,
               tile_size=1024, overlap=256):

    img = cv2.imread(img_path)
    h, w, _ = img.shape
    stride = tile_size - overlap

    labels = []
    if os.path.exists(label_path):
        with open(label_path) as f:
            labels = [list(map(float, l.split())) for l in f.readlines()]

    base = os.path.splitext(os.path.basename(img_path))[0]

    for y in range(0, h, stride):
        for x in range(0, w, stride):
            x2, y2 = min(x + tile_size, w), min(y + tile_size, h)
            tile = img[y:y2, x:x2]

            if tile.shape[0] < 200 or tile.shape[1] < 200:
                continue

            tile_labels = []
            for cls, xc, yc, bw, bh in labels:
                px, py = xc * w, yc * h
                bw *= w
                bh *= h

                if x <= px <= x2 and y <= py <= y2:
                    nx = (px - x) / (x2 - x)
                    ny = (py - y) / (y2 - y)
                    nw = bw / (x2 - x)
                    nh = bh / (y2 - y)
                    tile_labels.append([int(cls), nx, ny, nw, nh])

            tile_id = f"{base}_{x}_{y}"
            cv2.imwrite(f"{out_img_dir}/{tile_id}.jpg", tile)

            if tile_labels:
                with open(f"{out_lbl_dir}/{tile_id}.txt", "w") as f:
                    for l in tile_labels:
                        f.write(" ".join(map(str, l)) + "\n")

def tile_split(split):
    in_img = f"{YOLO_DATASET}/images/{split}"
    in_lbl = f"{YOLO_DATASET}/labels/{split}"
    out_img = f"{TILED_DATASET}/images/{split}"
    out_lbl = f"{TILED_DATASET}/labels/{split}"

    os.makedirs(out_img, exist_ok=True)
    os.makedirs(out_lbl, exist_ok=True)

    for img_name in tqdm(os.listdir(in_img), desc=f"Tiling {split}"):
        if not img_name.endswith(".jpg"):
            continue

        tile_image(
            f"{in_img}/{img_name}",
            f"{in_lbl}/{img_name.replace('.jpg', '.txt')}",
            out_img,
            out_lbl
        )

tile_split("train")
tile_split("val")

# Commented out IPython magic to ensure Python compatibility.
# %%writefile seadronessee.yaml
# 
# path: dataset_tiled
# train: images/train
# val: images/val
# 
# nc: 5
# names:
#   - swimmer
#   - boat
#   - jetski
#   - lifesaving_appliance
#   - buoy
#

model = YOLO("yolov8l.pt")

model.train(
    data="seadronessee.yaml",
    imgsz=640,
    epochs=20,
    batch=2,          # Safe for T4
    device=0,
    optimizer="AdamW",
    amp=True,
    cos_lr=True,
    workers=4,
    project="outputs",
    name="train"
)

outputs/train/weights/best.pt
outputs/train/results.csv